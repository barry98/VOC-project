{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: thinc.extra.search.Beam size changed, may indicate binary incompatibility. Expected 112 from C header, got 120 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import notebook\n",
    "import ast\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from datetime import datetime, timedelta\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_rank(rank, translator):\n",
    "    if rank in translator['(all occupations)'].tolist():\n",
    "        return translator.index[translator['(all occupations)'] == rank][0]\n",
    "    else:\n",
    "        return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\tqdm\\std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (17,27,35,36,38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e3ceb6803245e7807d0f32cae51a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ddd3e0e48a4ec7a6677838118b7e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=774200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "notebook.tqdm.pandas()\n",
    "clean = pd.read_csv('../../clean_data.csv')\n",
    "voc_df = pd.read_csv('../vocop-clustered-new.csv', sep='\t')\n",
    "uuid = []\n",
    "name = []\n",
    "for y, z in notebook.tqdm(clean.iterrows()):\n",
    "    for x in ast.literal_eval(z.namen):\n",
    "        if x['tussenvoegsel'] != None:\n",
    "            name.append(x['voornaam'] + \" \" + x['tussenvoegsel'] + \" \" + x['achternaam'])\n",
    "            uuid.append(z.uuid)\n",
    "        elif x['voornaam'] and x['achternaam'] != None:\n",
    "            name.append(x['voornaam'] + \" \" + x['achternaam'])\n",
    "            uuid.append(z.uuid)\n",
    "name_list = pd.DataFrame(data={'uuid':uuid, 'name':name}, columns=['uuid', 'name'])\n",
    "name_df = clean.merge(name_list)\n",
    "rangen = pd.read_excel('../../vocop_rangen.xlsx', index_col=0)\n",
    "voc_df['dutch_rank'] = [translate_rank(x, rangen) for x in notebook.tqdm(voc_df['rank'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_search(name, voc, distance):\n",
    "    names = np.where((voc.fullNameNormalized.apply(fuzz.ratio, args=[name]) >= 90) | \n",
    "                     (voc.fullNameOriginal.dropna().apply(fuzz.ratio, args=[name]) >= 90))\n",
    "    return names[0]\n",
    "\n",
    "def find_matches(names, voc, distance):\n",
    "    name_list = {}\n",
    "    final = []\n",
    "    for x in notebook.tqdm(names):\n",
    "        if x in name_list:\n",
    "            final.append((name_list[x]))\n",
    "        else:\n",
    "            result = fuzzy_search(x, voc, distance)\n",
    "            name_list[x] = result\n",
    "            final.append(result)\n",
    "    return final\n",
    "\n",
    "def get_voc_data(matches, voc):\n",
    "    if len(matches) != 0:\n",
    "        data = []\n",
    "        for index in matches:\n",
    "            holder = {}\n",
    "            holder['index'] = index\n",
    "            holder['name_original'] = voc.iloc[index].fullNameOriginal\n",
    "            holder['name_normalized'] = voc.iloc[index].fullNameNormalized\n",
    "            holder['date_out'] = voc.iloc[index].date_begin_service_complete\n",
    "            holder['date_return'] = voc.iloc[index].date_end_service_complete\n",
    "            holder['ship_out'] = voc.iloc[index].shipOutward\n",
    "            holder['ship_return'] = voc.iloc[index].shipReturn\n",
    "            holder['rank'] = voc.iloc[index]['dutch_rank']\n",
    "            holder['place_of_origin'] = voc.iloc[index].placeOfOrigin\n",
    "            data.append(holder)\n",
    "        return data\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_notary_matches(row, nlp):\n",
    "    holder = {}\n",
    "    if row.data_matches != 0:\n",
    "        for x in row.data_matches:\n",
    "            ship_out, ship_return = str(x['ship_out']), str(x['ship_return']) \n",
    "            rank, place_of_origin = str(x['rank']), str(x['place_of_origin'])\n",
    "            detected_ships = []\n",
    "            detected_ranks = []\n",
    "            detected_location = []\n",
    "            \n",
    "            # Find Ships\n",
    "            if fuzz.partial_ratio(ship_out.lower(), str(row.beschrijving).lower()) >= 80 or fuzz.partial_ratio(ship_out.lower(), row.text.lower()) >= 80:\n",
    "                    detected_ships.append(ship_out)\n",
    "            if fuzz.partial_ratio(ship_return.lower(), str(row.beschrijving).lower()) >= 80 or fuzz.partial_ratio(ship_return.lower(), row.text.lower()) >= 80:\n",
    "                    detected_ships.append(ship_return)\n",
    "\n",
    "            # Find Rank\n",
    "            if fuzz.partial_ratio(rank.lower(), str(row.beschrijving).lower()) >= 80 or fuzz.partial_ratio(rank.lower(), row.text.lower()) >= 80:\n",
    "                detected_ranks.append(rank)\n",
    "\n",
    "            # Find Place of Origin\n",
    "            if fuzz.partial_ratio(place_of_origin.lower(), str(row.beschrijving).lower()) >= 80 or fuzz.partial_ratio(place_of_origin.lower(), row.text.lower()) >= 80:\n",
    "                detected_location.append(place_of_origin)\n",
    "            else:\n",
    "                for ent in nlp(row.text).ents:\n",
    "                    if ent.label_ == 'LOC':\n",
    "                        if fuzz.ratio(place_of_origin, ent.text) >= 85:\n",
    "                            detected_location.append(place_of_origin)\n",
    "            holder[x['index']] = {'ships':detected_ships, 'rank':detected_ranks, 'location':detected_location}\n",
    "        return holder\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def create_annotation_subset(notary, voc):\n",
    "    nlp = spacy.load('nl_core_news_sm')\n",
    "    return_df = notary.copy()\n",
    "    return_df['index_matches'] = find_matches(return_df.name, voc, 80)\n",
    "    return_df['data_matches'] = return_df.index_matches.progress_apply(get_voc_data, args=[voc])\n",
    "    return_df = return_df.drop('index_matches', axis=1)\n",
    "    return_df['data_entry'] = return_df.progress_apply(get_notary_matches, args=[nlp], axis=1)\n",
    "    return return_df\n",
    "\n",
    "# def annotate(row):\n",
    "#     notary_date = datetime.strptime(row.datering, '%Y-%m-%d')\n",
    "#     if row.data_matches != '0':\n",
    "#         #print(row.data_matches)\n",
    "#         #for person in row.data_matches:\n",
    "#         for person in row.data_matches:\n",
    "#             try:\n",
    "#                 out_date = datetime.strptime(person['date_out'], '%Y-%m-%d')\n",
    "#             except:\n",
    "#                 out_date = datetime(year=1, month=1, day =1 )\n",
    "#             try:\n",
    "#                 return_date = datetime.strptime(person['date_return'], '%Y-%m-%d')\n",
    "#             except:\n",
    "#                 return_date = datetime(year=1, month=1, day =1 )\n",
    "#             if (notary_date - out_date).days not in range(0, -91, -1) and (notary_date - return_date).days not in range(0, 91):\n",
    "#                 #print('Skipped match')\n",
    "#                 continue\n",
    "                \n",
    "#             else:\n",
    "#                 print('{:10} | {:30} | {}'.format(' ', \"Notary Information \" + str(row.name), 'VOC Information ' + str(person['index'])))\n",
    "#                 print('-' * 108)\n",
    "#                 print('{:10} | {:30} | {} / {}'.format('Name', row['name'], person['name_original'], person['name_normalized']))\n",
    "#                 print('{:10} | {:30} | {} / {}'.format('Dates', row.datering, person['date_out'], person['date_return']))\n",
    "#                 print('{:10} | {:30} | {} / {}'.format('Ships', ' / '.join(row['data_entry'][str(person['index'])]['ships']), person['ship_out'], person['ship_return']))\n",
    "#                 print('{:10} | {:30} | {}'.format('Rank', ' / '.join(row['data_entry'][str(person['index'])]['rank']), person['rank']))\n",
    "#                 print('{:10} | {:30} | {}'.format('Locations', ' / '.join(row['data_entry'][str(person['index'])]['location']), person['place_of_origin']))\n",
    "#                 check = False\n",
    "#                 print('Are these persons the same? y/n:')\n",
    "#                 while check != True:\n",
    "#                     answer = input()\n",
    "#                     if answer == 'y':\n",
    "#                         return (person['name_original'], person['index'])\n",
    "#                         check = True\n",
    "#                     elif answer == 'n':\n",
    "#                         check = True\n",
    "#                     elif answer == 'text':\n",
    "#                         print(row.text)\n",
    "#                     else:\n",
    "#                         print(\"Invalid input please enter 'y', 'n', or 'text' without the quotes.\")\n",
    "#         return None\n",
    "                \n",
    "#     else:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(df, prev=None):\n",
    "    if prev is not None:\n",
    "        final = prev.copy()\n",
    "        start = len(final)\n",
    "    else:\n",
    "        final = pd.DataFrame(columns = df.columns)\n",
    "        start = 0\n",
    "    holder = []\n",
    "    #stop = False\n",
    "    #while stop != True:\n",
    "    for row in df[start:].itertuples():\n",
    "        notary_date = datetime.strptime(row.datering, '%Y-%m-%d')\n",
    "        if row.data_matches != '0':\n",
    "            #print(row.data_matches)\n",
    "            #for person in row.data_matches:\n",
    "            for person in row.data_matches:\n",
    "                try:\n",
    "                    out_date = datetime.strptime(person['date_out'], '%Y-%m-%d')\n",
    "                except:\n",
    "                    out_date = datetime(year=1, month=1, day =1 )\n",
    "                try:\n",
    "                    return_date = datetime.strptime(person['date_return'], '%Y-%m-%d')\n",
    "                except:\n",
    "                    return_date = datetime(year=1, month=1, day =1 )\n",
    "                if (notary_date - out_date).days not in range(0, -91, -1) and (notary_date - return_date).days not in range(0, 91):\n",
    "                    #print('Skipped match')\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    print('{:10} | {:30} | {}'.format(' ', \"Notary Information \" + str(row.name), 'VOC Information ' + str(person['index'])))\n",
    "                    print('-' * 108)\n",
    "                    print('{:10} | {:30} | {} / {}'.format('Name', row.name, person['name_original'], person['name_normalized']))\n",
    "                    print('{:10} | {:30} | {} / {}'.format('Dates', row.datering, person['date_out'], person['date_return']))\n",
    "                    print('{:10} | {:30} | {} / {}'.format('Ships', ' / '.join(row.data_entry[str(person['index'])]['ships']), person['ship_out'], person['ship_return']))\n",
    "                    print('{:10} | {:30} | {}'.format('Rank', ' / '.join(row.data_entry[str(person['index'])]['rank']), person['rank']))\n",
    "                    print('{:10} | {:30} | {}'.format('Locations', ' / '.join(row.data_entry[str(person['index'])]['location']), person['place_of_origin']))\n",
    "                    check = False\n",
    "                    print('Are these persons the same? y/n:')\n",
    "                    while check != True:\n",
    "                        answer = input()\n",
    "                        if answer == 'y':\n",
    "                            holder.append((person['name_original'], person['index']))\n",
    "                            final = final.append(df.loc[row.Index])\n",
    "                            check = True\n",
    "                        elif answer == 'n':\n",
    "                            check = True\n",
    "                        elif answer == 'text':\n",
    "                            print(row.text)\n",
    "                        elif answer == 'stop':\n",
    "                            final['vocop_match'][start:] = holder\n",
    "                            return final\n",
    "                        else:\n",
    "                            print(\"Invalid input please enter 'y', 'n', 'stop', or 'text' without the quotes.\")\n",
    "                    if answer == 'y':\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "            if answer == 'y':\n",
    "                continue\n",
    "            else:\n",
    "                holder.append(0)\n",
    "                final = final.append(df.loc[row.Index])\n",
    "        else:\n",
    "            holder.append(0)\n",
    "            final = final.append(df.loc[row.Index])\n",
    "    final['vocop_match'][start:] = holder\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#henk1 = create_annotation_subset(name_df[0:10].copy(), voc_df)\n",
    "#henk1 = create_annotation_subset(name_df[0:5000].copy(), voc_df)\n",
    "#henk1 = create_annotation_subset(name_df[54465:54467].copy(), voc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#henk1.to_json('subset1.json')\n",
    "#subset = pd.read_json('result.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t5t10 = create_annotation_subset(name_df[5000:10000].copy(), voc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t5t10.to_json('subset2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_json('subset1.json')\n",
    "sub2 = pd.read_json('subset2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub2[sub2.data_matches != 0][350:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[0:661].to_json('batch1_patrick.json')\n",
    "sub[661:1350].to_json('batch1_thom.json')\n",
    "sub[1350:1924].to_json('batch1_chiel.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[1924:2529].to_json('batch2_patrick.json')\n",
    "sub[2529:3134].to_json('batch2_thom.json')\n",
    "sub[3134:3797].to_json('batch2_chiel.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[3793:4416].to_json('batch3_patrick.json')\n",
    "sub[4416:5000].to_json('batch3_thom.json')\n",
    "sub2[0:611].to_json('batch3_chiel.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2[611:1226].to_json('batch1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (17,27,35,36,38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "voc_df = pd.read_csv('../vocop-clustered-new.csv', sep='\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
