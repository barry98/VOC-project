{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import notebook\n",
    "import ast\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from datetime import datetime, timedelta\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fleiss_kappa(ratings, n):\n",
    "    '''\n",
    "    Computes the Fleiss' kappa measure for assessing the reliability of \n",
    "    agreement between a fixed number n of raters when assigning categorical\n",
    "    ratings to a number of items.\n",
    "    \n",
    "    Args:\n",
    "        ratings: a list of (item, category)-ratings\n",
    "        n: number of raters\n",
    "        k: number of categories\n",
    "    Returns:\n",
    "        the Fleiss' kappa score\n",
    "    \n",
    "    See also:\n",
    "        http://en.wikipedia.org/wiki/Fleiss'_kappa\n",
    "    '''\n",
    "    items = set()\n",
    "    categories = set()\n",
    "    n_ij = {}\n",
    "    \n",
    "    for i, c in ratings:\n",
    "        items.add(i)\n",
    "        categories.add(c)\n",
    "        n_ij[(i,c)] = n_ij.get((i,c), 0) + 1\n",
    "    \n",
    "    N = len(items)\n",
    "    \n",
    "    p_j = dict(((c, sum(n_ij.get((i, c), 0) for i in items) / (1.0 * n * N)) for c in categories))\n",
    "    P_i = dict(((i, (sum(n_ij.get((i, c), 0) ** 2 for c in categories) - n) / (n * (n - 1.0))) for i in items))\n",
    "\n",
    "    P_bar = sum(P_i.values()) / (1.0 * N)\n",
    "    P_e_bar = sum(value ** 2 for value in p_j.values())\n",
    "    \n",
    "    kappa = (P_bar - P_e_bar) / (1 - P_e_bar)\n",
    "    \n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = [(1, 'yes')] * 10 + [(1, 'no')] * 0  + \\\n",
    "# [(2, 'yes')] * 8  + [(2, 'no')] * 2  + \\\n",
    "# [(3, 'yes')] * 9  + [(3, 'no')] * 1  + \\\n",
    "# [(4, 'yes')] * 0  + [(4, 'no')] * 10 + \\\n",
    "# [(5, 'yes')] * 7  + [(5, 'no')] * 3\n",
    "\n",
    "fleiss_kappa(ratings, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pat = pd.read_json('../../Annotation/Patrick/test_batch_patrick.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chiel = pd.read_json('../../Annotation/Chiel/test_batch_chiel.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "for x in range(len(subset2_bar[0:554])):\n",
    "    if subset2_bar.iloc[x].vocop_match == 0:\n",
    "        ratings.append((x + 1, 'no'))\n",
    "    else:\n",
    "        ratings.append((x + 1, 'yes'))\n",
    "    if subset2_bar.iloc[x].vocop_match == 0:\n",
    "        ratings.append((x + 1, 'no'))\n",
    "    else:\n",
    "        ratings.append((x + 1, 'yes'))\n",
    "    if test_pat.iloc[x].vocop_match == 0:\n",
    "        ratings.append((x + 1, 'no'))\n",
    "    else:\n",
    "        ratings.append((x + 1, 'yes'))\n",
    "    if test_chiel.iloc[x].vocop_match == 0:\n",
    "        ratings.append((x + 1, 'no'))\n",
    "    else:\n",
    "        ratings.append((x + 1, 'yes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((6**2) + (548**2) - 554) / (554 * (554 - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie = 0.9785351969239005 + 0.9785351969239005# + 0.971\n",
    "pie = pie/2\n",
    "pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pce = ((6 + 6) / (2* 554)) ** 2 + ((548 + 548) / (2* 554)) ** 2 \n",
    "print(pce)\n",
    "(pie - pce) / (1-pce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Completed Batches/'\n",
    "subset1_pat = pd.read_json(path + 'batch1_patrick_result.json')\n",
    "subset2_pat = pd.read_json(path + 'batch2_patrick_result.json')\n",
    "subset3_pat = pd.read_json(path + 'batch3_patrick_result.json')\n",
    "subset4_pat = pd.read_json(path + 'batch4_patrick_result.json')\n",
    "subset5_pat = pd.read_json(path + 'batch5_patrick_result.json')\n",
    "subset1_thom = pd.read_json(path + 'batch1_thom_result.json')\n",
    "subset1_chiel = pd.read_json(path + 'batch1_chiel_result.json')\n",
    "subset2_chiel = pd.read_json(path + 'batch2_chiel_result.json')\n",
    "subset3_chiel = pd.read_json(path + 'batch3_chiel_result.json')\n",
    "subset1_bar = pd.read_json(path + 'batch1_result.json')\n",
    "subset2_bar = pd.read_json(path + 'result.json')\n",
    "subset3_bar = pd.read_json(path + 'batch2_result.json')\n",
    "subset4_bar = pd.read_json(path + 'batch3_result.json')\n",
    "subset5_bar = pd.read_json(path + 'batch4_result.json')\n",
    "subset6_bar = pd.read_json(path + 'batch2_thom_result.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset2_bar[subset2_bar.vocop_match == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcties:\n",
    "Chiel:\n",
    "- Christiaan Andriesz 1416\n",
    "- Jan de Bruijn 1463\n",
    "- Abraham van de Heuvel (1823 super interessant twijfel geval)\n",
    "- Pieter van Essen (1825 super interessant twijfel geval)\n",
    "- Hans Pietersz 3792\n",
    "\n",
    "Patrick:\n",
    "- Jan Smit 4194 (zelde als de interessante gevallen van Chiel)\n",
    "- Hendrik van Alen 593 (zelfde schip maar naam is net even anders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1_pat.at[593, 'vocop_match'] = 0\n",
    "subset1_chiel.at[1416,'vocop_match'] = 0\n",
    "subset1_chiel.at[1463,'vocop_match'] = 0\n",
    "subset2_chiel.at[3729, 'vocop_match'] = 0\n",
    "subset4_bar.at[9025, 'vocop_match'] = ('Johannis Oosterhoff', 140442)\n",
    "subset5_bar.at[9927, 'vocop_match'] = ('Wiggert Andresz', 374198)\n",
    "subset6_bar.at[2670, 'vocop_match'] = ('Johan Christiaan Richter', 379155)\n",
    "subset6_bar.at[2688, 'vocop_match'] = ('Jacob Meijer', 178549)\n",
    "subset6_bar.at[2689, 'vocop_match'] = ('Juriaan Bartels', 178548)\n",
    "subset6_bar.at[2690, 'vocop_match'] = ('Willem Borsenius', 283179)\n",
    "subset6_bar.at[2691, 'vocop_match'] = ('Jan de Vaij', 182941)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pat = subset1_pat\n",
    "final_pat = final_pat.append(subset2_pat)\n",
    "final_pat = final_pat.append(subset3_pat).append(subset4_pat).append(subset5_pat)\n",
    "\n",
    "final_chiel = subset1_chiel\n",
    "final_chiel = final_chiel.append(subset2_chiel)\n",
    "final_chiel = final_chiel.append(subset3_chiel)\n",
    "\n",
    "final_barry = subset1_bar\n",
    "final_barry = final_barry.append(subset2_bar).append(subset3_bar).append(subset4_bar).append(subset5_bar).append(subset6_bar)\n",
    "\n",
    "final_df = final_pat.append(final_chiel).append(subset1_thom).append(final_barry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>rubriek</th>\n",
       "      <th>notaris</th>\n",
       "      <th>inventarisNr</th>\n",
       "      <th>akteNr</th>\n",
       "      <th>akteType</th>\n",
       "      <th>datering</th>\n",
       "      <th>taal</th>\n",
       "      <th>beschrijving</th>\n",
       "      <th>namen</th>\n",
       "      <th>urls</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "      <th>data_matches</th>\n",
       "      <th>data_entry</th>\n",
       "      <th>vocop_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>1bf4e148-14a4-dd4d-ef24-503a157766dc</td>\n",
       "      <td>358</td>\n",
       "      <td>JAN VERLEIJ</td>\n",
       "      <td>11960</td>\n",
       "      <td>21944</td>\n",
       "      <td>Machtiging</td>\n",
       "      <td>1766-08-25</td>\n",
       "      <td>nederlands</td>\n",
       "      <td>\\nVOC schip Damzigt, schip Walcheren, innen va...</td>\n",
       "      <td>[{'voornaam': 'Pieter', 'tussenvoegsel': 'van'...</td>\n",
       "      <td>['KLAB06468000354.JPG', 'KLAB06468000355.JPG',...</td>\n",
       "      <td>an No: 215 Procuratie gecasseerd den 25e: aug:...</td>\n",
       "      <td>Pieter van Kerkwijk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>1bf4e148-14a4-dd4d-ef24-503a157766dc</td>\n",
       "      <td>358</td>\n",
       "      <td>JAN VERLEIJ</td>\n",
       "      <td>11960</td>\n",
       "      <td>21944</td>\n",
       "      <td>Machtiging</td>\n",
       "      <td>1766-08-25</td>\n",
       "      <td>nederlands</td>\n",
       "      <td>\\nVOC schip Damzigt, schip Walcheren, innen va...</td>\n",
       "      <td>[{'voornaam': 'Pieter', 'tussenvoegsel': 'van'...</td>\n",
       "      <td>['KLAB06468000354.JPG', 'KLAB06468000355.JPG',...</td>\n",
       "      <td>an No: 215 Procuratie gecasseerd den 25e: aug:...</td>\n",
       "      <td>Hendrik Dames</td>\n",
       "      <td>[{'index': 55709, 'name_original': 'Hendrik Da...</td>\n",
       "      <td>{'55709': {'ships': [], 'rank': [], 'location'...</td>\n",
       "      <td>[Hendrik Dames, 80776]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>1bf4e148-14a4-dd4d-ef24-503a157766dc</td>\n",
       "      <td>358</td>\n",
       "      <td>JAN VERLEIJ</td>\n",
       "      <td>11960</td>\n",
       "      <td>21944</td>\n",
       "      <td>Machtiging</td>\n",
       "      <td>1766-08-25</td>\n",
       "      <td>nederlands</td>\n",
       "      <td>\\nVOC schip Damzigt, schip Walcheren, innen va...</td>\n",
       "      <td>[{'voornaam': 'Pieter', 'tussenvoegsel': 'van'...</td>\n",
       "      <td>['KLAB06468000354.JPG', 'KLAB06468000355.JPG',...</td>\n",
       "      <td>an No: 215 Procuratie gecasseerd den 25e: aug:...</td>\n",
       "      <td>Willem de Kemp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      uuid  rubriek      notaris  \\\n",
       "5963  1bf4e148-14a4-dd4d-ef24-503a157766dc      358  JAN VERLEIJ   \n",
       "5964  1bf4e148-14a4-dd4d-ef24-503a157766dc      358  JAN VERLEIJ   \n",
       "5965  1bf4e148-14a4-dd4d-ef24-503a157766dc      358  JAN VERLEIJ   \n",
       "\n",
       "      inventarisNr  akteNr    akteType    datering        taal  \\\n",
       "5963         11960   21944  Machtiging  1766-08-25  nederlands   \n",
       "5964         11960   21944  Machtiging  1766-08-25  nederlands   \n",
       "5965         11960   21944  Machtiging  1766-08-25  nederlands   \n",
       "\n",
       "                                           beschrijving  \\\n",
       "5963  \\nVOC schip Damzigt, schip Walcheren, innen va...   \n",
       "5964  \\nVOC schip Damzigt, schip Walcheren, innen va...   \n",
       "5965  \\nVOC schip Damzigt, schip Walcheren, innen va...   \n",
       "\n",
       "                                                  namen  \\\n",
       "5963  [{'voornaam': 'Pieter', 'tussenvoegsel': 'van'...   \n",
       "5964  [{'voornaam': 'Pieter', 'tussenvoegsel': 'van'...   \n",
       "5965  [{'voornaam': 'Pieter', 'tussenvoegsel': 'van'...   \n",
       "\n",
       "                                                   urls  \\\n",
       "5963  ['KLAB06468000354.JPG', 'KLAB06468000355.JPG',...   \n",
       "5964  ['KLAB06468000354.JPG', 'KLAB06468000355.JPG',...   \n",
       "5965  ['KLAB06468000354.JPG', 'KLAB06468000355.JPG',...   \n",
       "\n",
       "                                                   text                 name  \\\n",
       "5963  an No: 215 Procuratie gecasseerd den 25e: aug:...  Pieter van Kerkwijk   \n",
       "5964  an No: 215 Procuratie gecasseerd den 25e: aug:...        Hendrik Dames   \n",
       "5965  an No: 215 Procuratie gecasseerd den 25e: aug:...       Willem de Kemp   \n",
       "\n",
       "                                           data_matches  \\\n",
       "5963                                                  0   \n",
       "5964  [{'index': 55709, 'name_original': 'Hendrik Da...   \n",
       "5965                                                  0   \n",
       "\n",
       "                                             data_entry  \\\n",
       "5963                                                  0   \n",
       "5964  {'55709': {'ships': [], 'rank': [], 'location'...   \n",
       "5965                                                  0   \n",
       "\n",
       "                 vocop_match  \n",
       "5963                       0  \n",
       "5964  [Hendrik Dames, 80776]  \n",
       "5965                       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_df = final_df.loc[~final_df.index.duplicated(keep='first')]\n",
    "# final_df.index.name = 'index'\n",
    "# final_df.to_csv('../final_df.csv', index=True)\n",
    "final_df[final_df.vocop_match != 0]\n",
    "final_df[final_df.uuid == '1bf4e148-14a4-dd4d-ef24-503a157766dc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc.iloc[80776]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc[voc.VOCOP_id == 422482]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('nl_core_news_sm', disable=['parser', 'tagger', 'textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_neighbour(start, end, true, prev, distance):\n",
    "    if true == []:\n",
    "        return (start, end), prev.i\n",
    "    if prev.i == len(prev.doc) - 1:\n",
    "        return (start, end), prev.i\n",
    "    if fuzz.ratio(true[0].lower(), prev.nbor().text.lower()) >= distance:\n",
    "        return match_neighbour(start, prev.nbor().idx + len(prev.nbor()), true[1:], prev.nbor(), distance)\n",
    "    else:\n",
    "        return (start, end), prev.i\n",
    "\n",
    "def match_finder(row, match, distance):\n",
    "\n",
    "    true = match\n",
    "    doc = nlp(row.text)\n",
    "    locs = []\n",
    "    prev = 0\n",
    "    for token in doc:\n",
    "            for x in true:\n",
    "                if token.i > prev and type(x) == str:\n",
    "                    split = x.split(' ')\n",
    "                    if fuzz.ratio(split[0].lower(), token.text.lower()) >= distance:\n",
    "                        result, prev = match_neighbour(token.idx, token.idx + len(token), split[1:], token, distance)\n",
    "                        if result not in locs:\n",
    "                            if fuzz.ratio(row.text[result[0]:result[1]], x) >= distance:\n",
    "                                locs.append(result)\n",
    "    entities = [row.text[x[0]:x[1]] for x in locs]\n",
    "    return entities\n",
    "\n",
    "def fix_entries_ships(row, x):\n",
    "    ships = match_finder(row, [x['shipOutward'], x['shipReturn']], 80)\n",
    "    rank =  match_finder(row, [x['dutch_rank']], 80)\n",
    "    location = match_finder(row, [x['placeOfOrigin']], 90)\n",
    "#     keywords = match_finder(row, ['kamer van zeeland', 'kamer zeeland', 'kamer van amsterdam', 'kamer amsterdam', \n",
    "#                                   'kamer van hoorn', 'kamer hoorn', 'kamer enkhuizen', 'kamer van enkhuizen',\n",
    "#                                   'kamer delft', 'kamer van delft', 'oostindische compagnie', 'oostindie compagnie',\n",
    "#                                   'oostindie'], 80)\n",
    "    true_data_matches = {'ships': ships, 'location':location, 'rank':rank}#, 'keywords':keywords}\n",
    "    return true_data_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (17,27,35,36,38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "voc = pd.read_csv('../vocop_clustered_dutchrank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = pd.DataFrame(columns=['name_ratio', 'name_count', 'day_dif', 'location', 'rank', 'numships', 'keywords', 'match', 'notary_id', 'voc_id'])\n",
    "name_dict = voc.fullNameNormalized.value_counts()\n",
    "for x in notebook.tqdm(final_df[final_df.data_matches != 0].itertuples(), total=final_df[final_df.data_matches != 0].shape[0]):\n",
    "    notary_date = datetime.strptime(x.datering, '%Y-%m-%d')\n",
    "    notid = x.Index\n",
    "    for match in x.data_matches:\n",
    "        index = str(x.Index) + '_' + str(match['index'])\n",
    "        vocid=match['index']\n",
    "        name_ratio=max(fuzz.ratio(x.name, match['name_original']), fuzz.ratio(x.name, match['name_normalized']))\n",
    "        name_count = name_dict[match['name_normalized']]\n",
    "        \n",
    "        if x.vocop_match != 0 and match['index'] == x.vocop_match[1]:\n",
    "            matched = 1\n",
    "        else:\n",
    "            matched = 0\n",
    "        \n",
    "        try:\n",
    "            out_date = datetime.strptime(match['date_out'], '%Y-%m-%d')\n",
    "        except:\n",
    "            out_date = datetime(year=1, month=1, day =1 )\n",
    "        try:\n",
    "            return_date = datetime.strptime(match['date_return'], '%Y-%m-%d')\n",
    "        except:\n",
    "            return_date = datetime(year=1, month=1, day =1 )\n",
    "        if (notary_date - out_date).days in range(0, -91, -1):\n",
    "            day_dif = -(notary_date - out_date).days\n",
    "        elif (notary_date - return_date).days in range(0, 91):\n",
    "            day_dif = (notary_date - return_date).days\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if str(match['index']) in x.data_entry:\n",
    "            ship_matches = fix_entries_ships(x, match)\n",
    "            numships = len(ship_matches['ships'])\n",
    "            if ship_matches['rank'] != []:\n",
    "                rank = 1\n",
    "            else:\n",
    "                rank = 0\n",
    "            if ship_matches['location'] != []:\n",
    "                location = 1\n",
    "            else:\n",
    "                location = 0\n",
    "            if ship_matches['keywords'] != []:\n",
    "                keywords = 1\n",
    "            else:\n",
    "                keywords = 0\n",
    "        else:\n",
    "            numships = 0\n",
    "            rank = 0\n",
    "            location = 0\n",
    "        tempdf = pd.DataFrame(columns=['name_ratio', 'name_count', 'day_dif', 'location', 'rank', 'numships', 'keywords', 'match', 'notary_id', 'voc_id'], data={\n",
    "            'name_ratio':name_ratio,\n",
    "            'name_count':name_count,\n",
    "            'day_dif':day_dif, \n",
    "            'location':location,\n",
    "            'rank':rank,\n",
    "            'numships':numships,\n",
    "            'keywords':keywords,\n",
    "            'match':matched,\n",
    "            'notary_id':notid,\n",
    "            'voc_id':vocid\n",
    "        }, index=[index])\n",
    "        ranking_df = ranking_df.append(tempdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df.to_csv('../preranking.csv', index=False)\n",
    "#final_df.to_csv('../final_df.csv')\n",
    "#ranking_df[ranking_df.match == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(final_df, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_neighbour(start, end, true, prev, distance):\n",
    "    if true == []:\n",
    "        return (start, end), prev.i\n",
    "    if prev.i == len(prev.doc) - 1:\n",
    "        return (start, end), prev.i\n",
    "    if fuzz.ratio(true[0].lower(), prev.nbor().text.lower()) >= distance:\n",
    "        return match_neighbour(start, prev.nbor().idx + len(prev.nbor()), true[1:], prev.nbor(), distance)\n",
    "    else:\n",
    "        return (start, end), prev.i\n",
    "\n",
    "def match_finder(row, match, distance):\n",
    "\n",
    "    true = match\n",
    "    doc = nlp(row.text)\n",
    "    locs = []\n",
    "    prev = 0\n",
    "    for token in doc:\n",
    "        for x in true:\n",
    "            if type(x) == str:\n",
    "                new_token = []\n",
    "                split = x.split(' ')\n",
    "                for y in range(len(split)):\n",
    "                    if token.i <= doc[-len(split)].i:\n",
    "                        new_token.append(token.nbor(y).text)\n",
    "                new_token_text = ' '.join(new_token)\n",
    "                if fuzz.ratio(x.lower(), new_token_text.lower()) >= distance:\n",
    "                    result = (token.idx, token.idx + len(new_token_text))\n",
    "                    if result not in locs:\n",
    "                        if fuzz.ratio(row.text[result[0]:result[1]].lower(), x.lower()) >= distance:\n",
    "                            locs.append(result)\n",
    "    entities = [row.text[x[0]:x[1]] for x in locs]\n",
    "    return entities\n",
    "\n",
    "def fix_entries_ships(row, x, column):\n",
    "    if type(x[column]) != float: \n",
    "        match = match_finder(row, [x[column]], 80) \n",
    "    else:\n",
    "        match = ''\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_finder(final_df.loc[2690],['Huis ter Duine'], 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[3171]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dedupe Record Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2384a4297b4e4005bbd32a060e9cad9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6832), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_n = {}\n",
    "data_v = {}\n",
    "df = train\n",
    "for x in notebook.tqdm(range(len(df))):\n",
    "    row = df.iloc[x]\n",
    "    holder = []\n",
    "    if row.data_matches != 0:\n",
    "        notary_date = datetime.strptime(row.datering, '%Y-%m-%d')\n",
    "        \n",
    "        for match in row.data_matches:\n",
    "            try:\n",
    "                out_date = datetime.strptime(match['date_out'], '%Y-%m-%d')\n",
    "            except:\n",
    "                out_date = datetime(year=1, month=1, day =1 )\n",
    "            try:\n",
    "                return_date = datetime.strptime(match['date_return'], '%Y-%m-%d')\n",
    "            except:\n",
    "                return_date = datetime(year=1, month=1, day =1 )\n",
    "            if (notary_date - out_date).days in range(0, -91, -1):\n",
    "                day_dif = -(notary_date - out_date).days\n",
    "            elif (notary_date - return_date).days in range(0, 91):\n",
    "                day_dif = (notary_date - return_date).days\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            found_ship_out = fix_entries_ships(row, voc.iloc[match['index']], 'shipOutward')\n",
    "            found_ship_return = fix_entries_ships(row, voc.iloc[match['index']], 'shipReturn')\n",
    "            found_loc = fix_entries_ships(row, voc.iloc[match['index']], 'placeOfOrigin')\n",
    "            found_rank = fix_entries_ships(row, voc.iloc[match['index']], 'dutch_rank')\n",
    "            holder.append({'rank':found_rank, 'location':found_loc, 'found_ship_return': found_ship_return, 'found_ship_out': found_ship_out})\n",
    "            \n",
    "            if row.vocop_match != 0 and match['index'] == row.vocop_match[1]:\n",
    "                cluster = df.iloc[x].name\n",
    "            else:\n",
    "                cluster = -int(voc.iloc[match['index']].VOCOP_id)\n",
    "            name = str(voc.iloc[match['index']].fullNameOriginal)\n",
    "            rang = str(voc.iloc[match['index']].dutch_rank)\n",
    "            loc = str(voc.iloc[match['index']].placeOfOrigin)\n",
    "            ship_out = str(voc.iloc[match['index']].shipOutward) \n",
    "            ship_return = str(voc.iloc[match['index']].shipReturn)\n",
    "            data_v[-int(voc.iloc[match['index']].VOCOP_id)] = {'cluster_id': cluster, 'name':name, 'rank':rang, 'location':loc, 'ship_out': ship_out, 'ship_return': ship_return}\n",
    "    name = row['name']\n",
    "    if holder == []:\n",
    "        rang = None\n",
    "        location = None\n",
    "        ship_out= None\n",
    "        ship_return = None\n",
    "    \n",
    "    else:\n",
    "        rang = ' | '.join(set([y.lower() for x in holder for y in x['rank']]))\n",
    "        if rang == '':\n",
    "            rang = None\n",
    "        location = ' | '.join(set([y.lower() for x in holder for y in x['location']]))\n",
    "        if location == '':\n",
    "            location = None\n",
    "        ship_out = ' | '.join(set([y.lower() for x in holder for y in x['found_ship_out']]))\n",
    "        if ship_out == '':\n",
    "            ship_return = None\n",
    "        ship_return = ' | '.join(set([y.lower() for x in holder for y in x['found_ship_return']]))\n",
    "        if ship_return == '':\n",
    "            ship_return = None\n",
    "    data_n[df.iloc[x].name] = {'cluster_id': df.iloc[x].name, 'name':name, 'rank':rang, 'location':location, 'ship_out': ship_out, 'ship_return': ship_return}\n",
    "\n",
    "d_n = {'cluster_id': [data_n[x]['cluster_id'] for x in data_n], 'name': [data_n[x]['name'] for x in data_n], 'rank':[data_n[x]['rank'] for x in data_n],\n",
    "     'location':[data_n[x]['location'] for x in data_n], 'ship_out': [data_n[x]['ship_out'] for x in data_n], 'ship_return': [data_n[x]['ship_return'] for x in data_n]}\n",
    "\n",
    "d_v = {'cluster_id': [data_v[x]['cluster_id'] for x in data_v], 'name': [data_v[x]['name'] for x in data_v], 'rank':[data_v[x]['rank'] for x in data_v],\n",
    "     'location':[data_v[x]['location'] for x in data_v], 'ship_out': [data_v[x]['ship_out'] for x in data_v], 'ship_return': [data_v[x]['ship_return'] for x in data_v]}\n",
    "\n",
    "dedupe_notary = pd.DataFrame(d_n)\n",
    "dedupe_notary.index.name = 'index'\n",
    "dedupe_notary.to_csv('../train_notary.csv')\n",
    "dedupe_voc = pd.DataFrame(d_v)\n",
    "dedupe_voc.index.name = 'index'\n",
    "dedupe_voc.to_csv('../train_voc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3022cd53751a4b3f92922e34f55c58c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_n = {}\n",
    "data_v = {}\n",
    "df = test\n",
    "for x in notebook.tqdm(range(len(df))):\n",
    "    row = df.iloc[x]\n",
    "    holder = []\n",
    "    if row.data_matches != 0:\n",
    "        notary_date = datetime.strptime(row.datering, '%Y-%m-%d')\n",
    "        \n",
    "        for match in row.data_matches:\n",
    "            try:\n",
    "                out_date = datetime.strptime(match['date_out'], '%Y-%m-%d')\n",
    "            except:\n",
    "                out_date = datetime(year=1, month=1, day =1 )\n",
    "            try:\n",
    "                return_date = datetime.strptime(match['date_return'], '%Y-%m-%d')\n",
    "            except:\n",
    "                return_date = datetime(year=1, month=1, day =1 )\n",
    "            if (notary_date - out_date).days in range(0, -91, -1):\n",
    "                day_dif = -(notary_date - out_date).days\n",
    "            elif (notary_date - return_date).days in range(0, 91):\n",
    "                day_dif = (notary_date - return_date).days\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            found_ship_out = fix_entries_ships(row, voc.iloc[match['index']], 'shipOutward')\n",
    "            found_ship_return = fix_entries_ships(row, voc.iloc[match['index']], 'shipReturn')\n",
    "            found_loc = fix_entries_ships(row, voc.iloc[match['index']], 'placeOfOrigin')\n",
    "            found_rank = fix_entries_ships(row, voc.iloc[match['index']], 'dutch_rank')\n",
    "            holder.append({'rank':found_rank, 'location':found_loc, 'found_ship_return': found_ship_return, 'found_ship_out': found_ship_out})\n",
    "            \n",
    "            if row.vocop_match != 0 and match['index'] == row.vocop_match[1]:\n",
    "                cluster = df.iloc[x].name\n",
    "            else:\n",
    "                cluster = -int(voc.iloc[match['index']].VOCOP_id)\n",
    "            name = str(voc.iloc[match['index']].fullNameOriginal)\n",
    "            rang = str(voc.iloc[match['index']].dutch_rank)\n",
    "            loc = str(voc.iloc[match['index']].placeOfOrigin)\n",
    "            ship_out = str(voc.iloc[match['index']].shipOutward) \n",
    "            ship_return = str(voc.iloc[match['index']].shipReturn)\n",
    "            data_v[-int(voc.iloc[match['index']].VOCOP_id)] = {'cluster_id': cluster, 'name':name, 'rank':rang, 'location':loc, 'ship_out': ship_out, 'ship_return': ship_return}\n",
    "    name = row['name']\n",
    "    if holder == []:\n",
    "        rang = None\n",
    "        location = None\n",
    "        ship_out= None\n",
    "        ship_return = None\n",
    "    \n",
    "    else:\n",
    "        rang = ' | '.join(set([y.lower() for x in holder for y in x['rank']]))\n",
    "        if rang == '':\n",
    "            rang = None\n",
    "        location = ' | '.join(set([y.lower() for x in holder for y in x['location']]))\n",
    "        if location == '':\n",
    "            location = None\n",
    "        ship_out = ' | '.join(set([y.lower() for x in holder for y in x['found_ship_out']]))\n",
    "        if ship_out == '':\n",
    "            ship_return = None\n",
    "        ship_return = ' | '.join(set([y.lower() for x in holder for y in x['found_ship_return']]))\n",
    "        if ship_return == '':\n",
    "            ship_return = None\n",
    "    data_n[df.iloc[x].name] = {'cluster_id': df.iloc[x].name, 'name':name, 'rank':rang, 'location':location, 'ship_out': ship_out, 'ship_return': ship_return}\n",
    "\n",
    "d_n = {'cluster_id': [data_n[x]['cluster_id'] for x in data_n], 'name': [data_n[x]['name'] for x in data_n], 'rank':[data_n[x]['rank'] for x in data_n],\n",
    "     'location':[data_n[x]['location'] for x in data_n], 'ship_out': [data_n[x]['ship_out'] for x in data_n], 'ship_return': [data_n[x]['ship_return'] for x in data_n]}\n",
    "\n",
    "d_v = {'cluster_id': [data_v[x]['cluster_id'] for x in data_v], 'name': [data_v[x]['name'] for x in data_v], 'rank':[data_v[x]['rank'] for x in data_v],\n",
    "     'location':[data_v[x]['location'] for x in data_v], 'ship_out': [data_v[x]['ship_out'] for x in data_v], 'ship_return': [data_v[x]['ship_return'] for x in data_v]}\n",
    "\n",
    "dedupe_notary = pd.DataFrame(d_n)\n",
    "dedupe_notary.index.name = 'index'\n",
    "dedupe_notary.to_csv('../test_notary.csv')\n",
    "dedupe_voc = pd.DataFrame(d_v)\n",
    "dedupe_voc.index.name = 'index'\n",
    "dedupe_voc.to_csv('../test_voc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test[test.vocop_match != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16 / 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "26 * 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedupe_notary[dedupe_notary.isna().ship_return == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedupe_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_finder(row, match, distance):\n",
    "\n",
    "    if len(match) >  1 and match[1] == 'schip':\n",
    "        true = [match[0]]\n",
    "        ship_check = True\n",
    "    else:\n",
    "        true = match\n",
    "        ship_check = False\n",
    "    doc = nlp(row.text)\n",
    "    locs = []\n",
    "    prev = 0\n",
    "    for token in doc:\n",
    "        for x in true:\n",
    "            if type(x) == str:\n",
    "                new_token = []\n",
    "                split = x.split(' ')\n",
    "                for y in range(len(split)):\n",
    "                    if token.i <= doc[-len(split)].i:\n",
    "                        new_token.append(token.nbor(y).text)\n",
    "                new_token_text = ' '.join(new_token)\n",
    "                if fuzz.ratio(x.lower(), new_token_text.lower()) >= distance:\n",
    "                    result = (token.idx, token.idx + len(new_token_text))\n",
    "                    if result not in locs:\n",
    "                        if fuzz.ratio(row.text[result[0]:result[1]].lower(), x.lower()) >= distance:\n",
    "                            locs.append(result)\n",
    "    if ship_check == True and locs == []:\n",
    "        knowledgebase = voc[(voc.yearBeginService.isin([row.jaar, str(int(row.jaar) - 1), str(int(row.jaar) + 1)])) | \n",
    "                            (voc.year_end_service_improved.isin([row.jaar, str(int(row.jaar) - 1), str(int(row.jaar) + 1)]))\n",
    "                           ]\n",
    "        ships = set(knowledgebase.shipOutward.str.lower().to_list() + \n",
    "                    knowledgebase.shipReturn.str.lower().to_list())\n",
    "        if len(match) > 2:\n",
    "            if str(match[2][0]).lower() in ships:\n",
    "                ships.remove(str(match[2][0]).lower())\n",
    "            if str(match[2][1]).lower() in ships:\n",
    "                ships.remove(str(match[2][1]).lower())\n",
    "        for token in doc:\n",
    "            if fuzz.ratio('schip', token.text.lower()) >= distance:\n",
    "                for x in ships:\n",
    "                    if type(x) == str:\n",
    "                        new_token = []\n",
    "                        split = x.split(' ')\n",
    "                        for y in range(len(split)):\n",
    "                            if token.nbor().i <= doc[-len(split)].i:\n",
    "                                new_token.append(token.nbor(1 + y).text)\n",
    "                        new_token_text = ' '.join(new_token)\n",
    "                        if fuzz.ratio(x.lower(), new_token_text.lower()) >= distance:\n",
    "                            result = (token.nbor().idx, token.nbor().idx + len(new_token_text))\n",
    "                            if result not in locs:\n",
    "                                if fuzz.ratio(row.text[result[0]:result[1]].lower(), x.lower()) >= distance:\n",
    "                                    locs.append(result)\n",
    "    entities = [row.text[x[0]:x[1]] for x in locs]\n",
    "    return entities\n",
    "\n",
    "def fix_entries_ships(row, x, column):\n",
    "    if column == 'shipOutward' or column == 'shipReturn':\n",
    "        if type(x[column]) != float:\n",
    "            match = match_finder(row, [x[column], 'schip', (x['shipOutward'], x['shipReturn'])], 80)\n",
    "        else:\n",
    "            match = match_finder(row, ['schip'], 80)\n",
    "    elif type(x[column]) != float: \n",
    "        match = match_finder(row, [x[column]], 80) \n",
    "    else:\n",
    "        match = ''\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['jaar'] = [x[0:4] for x in final_df.datering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-48d9c76c404b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m voc[(voc.yearBeginService.isin([y, str(int(y) - 1), str(int(y) + 1)])) | \n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear_end_service_improved\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m    ].shipOutward.str.lower().to_list()\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'dict'"
     ]
    }
   ],
   "source": [
    "voc[(voc.yearBeginService.isin([y, str(int(y) - 1), str(int(y) + 1)])) | \n",
    "    (voc.year_end_service_improved.isin([y, str(int(y) - 1), str(int(y) + 1)]))\n",
    "   ].shipOutward.str.lower().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515960629a5e4d778a657735813c921b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=102), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nieuland']\n",
      "['Zaamslad']\n",
      "['Nieuland']\n",
      "['Diemen', 'dien']\n",
      "['Anna']\n",
      "['Anna']\n",
      "['dAnna']\n",
      "['blommendaal']\n",
      "['Sloterdijk']\n",
      "['Sulpenbirg']\n",
      "['rotterdam']\n",
      "['perzijneburg']\n",
      "['Eendragt']\n",
      "['Westriesland']\n",
      "['Kievitsheuwel']\n",
      "['Hillegom']\n",
      "['aarmslag', 'Laamslagh']\n",
      "['guntersteijn']\n",
      "['Schellag']\n",
      "['Anna']\n",
      "['Leijden']\n",
      "['ouwerkerk']\n",
      "['Eendragt']\n",
      "['haerlem']\n",
      "['Voorzigtigheijd']\n",
      "['Nennieuwenkerk']\n",
      "['Vrouw Petronella']\n",
      "['Admiraal de Ruijter']\n",
      "['Borselen']\n",
      "['gustaaff Willen']\n",
      "['Langeuijk']\n",
      "['Buijdorp']\n",
      "['Buijdorp']\n",
      "['sgravezonde']\n",
      "['aschat']\n",
      "['s Lands welvaren']\n",
      "['Velsen']\n",
      "['Cortuijn']\n",
      "['brouwen']\n",
      "['huijs te Manpad']\n",
      "['tevreden']\n",
      "['Kasteel van Tilburg']\n",
      "['Stadwijk']\n",
      "['Westerveld']\n",
      "['Cattendijk']\n",
      "['Borselen']\n",
      "['getrouwigheijd']\n",
      "['Walcheren']\n",
      "['Schip Noordnieuwland', 'Noordnieuwland voor']\n",
      "['Pallas']\n",
      "['de vrouwellisabeth']\n",
      "['Vredenhoffte']\n",
      "['Akerendam']\n",
      "['Akerendam']\n",
      "['nieuw Walcheren']\n",
      "['Diemen']\n",
      "['Sloterdijk']\n",
      "['Kasteel van Tilburg']\n",
      "['Sloten']\n",
      "['Duijnenburg']\n",
      "['Leijden']\n",
      "['Baarsande']\n",
      "['Luxemburg']\n",
      "['Langewijk']\n",
      "['Brouwer']\n",
      "['Leijden']\n",
      "['Vosmaer']\n",
      "['haerlem']\n",
      "['haerlem']\n",
      "['huijs ten Duijnen']\n",
      "['huijs ten Duijnen']\n",
      "['huijs ten Duijnen']\n",
      "['Immegonda']\n",
      "['Jager']\n",
      "['Bloemendaal']\n",
      "['Wiekenburg']\n",
      "\n",
      "76 102\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "total = 0\n",
    "for x in notebook.tqdm(final_df[final_df.vocop_match != 0].itertuples(), total=final_df[final_df.vocop_match != 0].shape[0]):\n",
    "    for y in x.data_matches:\n",
    "        if y['index'] == x.vocop_match[1]:\n",
    "            test = fix_entries_ships(x, voc.iloc[y['index']], 'shipOutward')\n",
    "            if test != '':\n",
    "                total += 1\n",
    "            if test not in [[], '']:\n",
    "                c += 1\n",
    "                print(test)\n",
    "#             else:\n",
    "#                 print(x.Index)\n",
    "#                 print(x.beschrijving)\n",
    "#                 print(voc.iloc[y['index']]['shipOutward'])\n",
    "                \n",
    "                \n",
    "print(c, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d779bb25593843d79922c7db21191204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=102), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zaamslad']\n",
      "['Zaamslad']\n",
      "['Zaamslad']\n",
      "['Diemen', 'dien']\n",
      "['Schip']\n",
      "['dAnna']\n",
      "['Schip']\n",
      "['Sloterdijk']\n",
      "['Standvastigheijd']\n",
      "['Sulpenbirg']\n",
      "['Jaers', 'Jager']\n",
      "['Schip']\n",
      "['perzijneburg']\n",
      "['Schip']\n",
      "['Marienbss']\n",
      "['Westriesland']\n",
      "['Kievitsheuwel']\n",
      "['Hillegom']\n",
      "['aarmslag', 'Laamslagh']\n",
      "['Arnesteijn']\n",
      "['Schellag']\n",
      "['Schip']\n",
      "['Leijden']\n",
      "['bosbeek', 'Bosbeek']\n",
      "['haerlem']\n",
      "['osdorp']\n",
      "['Noterdijk']\n",
      "['Leckerlust']\n",
      "['Admiraal de Ruijter']\n",
      "['Wildrijk']\n",
      "['Leekenland']\n",
      "['Bosschenhoven']\n",
      "['vrouw Elisabeth']\n",
      "['vrouw Elisabeth']\n",
      "['sgravezonde']\n",
      "['Schip']\n",
      "['s Lands welvaren']\n",
      "['Velsen']\n",
      "['Schip']\n",
      "['Kasteel van Tilburg']\n",
      "['Duijnenbur']\n",
      "['de drie papezaijen']\n",
      "['Westerveld']\n",
      "['de vrouw ElisabethOorothea', 'vrouw ElisabethOorothea voor']\n",
      "['Borselen']\n",
      "['Jerusalen']\n",
      "['Damzigt']\n",
      "['Noordnieuwland voor']\n",
      "['Pallas']\n",
      "['Schip', 'Schip', 'Schip']\n",
      "['Schip']\n",
      "['Akerendam']\n",
      "['Akerendam']\n",
      "['krabbendijke']\n",
      "['Crabbendijk']\n",
      "['Crabbendijk']\n",
      "['Anna']\n",
      "['Sloterdijk']\n",
      "['Schip']\n",
      "['Sloten']\n",
      "['Duijnenburg']\n",
      "['Schip']\n",
      "['Baarsande']\n",
      "['Luxemburg']\n",
      "['huijs ten Douk']\n",
      "['Brouwer']\n",
      "['Schip']\n",
      "['Huijgewaerd']\n",
      "['Vosmaer']\n",
      "['Jager', 'Jager']\n",
      "['Jager', 'Jager']\n",
      "['huijs ten Duijnen']\n",
      "['huijs ten Duijnen']\n",
      "['huijs ten Duijnen']\n",
      "['huijs ten Duijnen']\n",
      "['Jager']\n",
      "['Schip']\n",
      "['Bloemendaal']\n",
      "['Baarzonde']\n",
      "\n",
      "79 102\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "total = 0\n",
    "for x in notebook.tqdm(final_df[final_df.vocop_match != 0].itertuples(), total=final_df[final_df.vocop_match != 0].shape[0]):\n",
    "    for y in x.data_matches:\n",
    "        if y['index'] == x.vocop_match[1]:\n",
    "            test = fix_entries_ships(x, voc.iloc[y['index']], 'shipReturn')\n",
    "            if test != '':\n",
    "                total += 1\n",
    "            if test not in [[], '']:\n",
    "                c += 1\n",
    "                print(test)\n",
    "                \n",
    "print(c, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "total = 0\n",
    "for x in notebook.tqdm(final_df[final_df.vocop_match != 0].itertuples(), total=final_df[final_df.vocop_match != 0].shape[0]):\n",
    "    for y in x.data_matches:\n",
    "        if y['index'] == x.vocop_match[1]:\n",
    "            test = fix_entries_ships(x, voc.iloc[y['index']], 'dutch_rank')\n",
    "            if test != '':\n",
    "                total += 1\n",
    "            if test not in [[], '']:\n",
    "                c += 1\n",
    "                \n",
    "print(c, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "total = 0\n",
    "for x in notebook.tqdm(final_df[final_df.vocop_match != 0].itertuples(), total=final_df[final_df.vocop_match != 0].shape[0]):\n",
    "    for y in x.data_matches:\n",
    "        if y['index'] == x.vocop_match[1]:\n",
    "            test = fix_entries_ships(x, voc.iloc[y['index']], 'placeOfOrigin')\n",
    "            if test != '':\n",
    "                total += 1\n",
    "            if test not in [[], '']:\n",
    "                c += 1\n",
    "                \n",
    "print(c, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[7280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
